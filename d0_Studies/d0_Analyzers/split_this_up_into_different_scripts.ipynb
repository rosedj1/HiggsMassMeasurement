{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'perc_diff' from 'PyUtils.Utils_Physics' (/Users/Jake/HiggsMassMeasurement/PyUtils/Utils_Physics.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-337de797c978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                     \u001b[0madd_underoverflow_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_stats_legend_for_1dhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_stats_legend_for_2dhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                     make_stats_legend_for_gaus_fit)\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils_Physics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheta2pseudorap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpseudorap2theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_dR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_dphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils_StatsAndFits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_with_gaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterative_fit_gaus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils_Collection_Helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweave_lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'perc_diff' from 'PyUtils.Utils_Physics' (/Users/Jake/HiggsMassMeasurement/PyUtils/Utils_Physics.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/Users/Jake/')\n",
    "sys.path.append('/Users/Jake/HiggsMassMeasurement/')\n",
    "sys.path.append('/Users/Jake/HiggsMassMeasurement/d0_Studies/')\n",
    "\n",
    "# Neat tricks.\n",
    "from itertools import chain\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Local imports. \n",
    "from PyUtils.Utils_Files import makeDirs, make_str_title_friendly, check_overwrite\n",
    "from PyUtils.Utils_Plotting import (change_cmap_bkg_to_white, save_plots_to_outpath, make_1D_dist, get_stats_1Dhist, \n",
    "                                    get_stats_2Dhist, hist_y_label, make_2by2_subplots_for_ratioplots,\n",
    "                                    add_underoverflow_entries, make_stats_legend_for_1dhist, make_stats_legend_for_2dhist, \n",
    "                                    make_stats_legend_for_gaus_fit)\n",
    "from PyUtils.Utils_Physics import theta2pseudorap, pseudorap2theta, calc_dR, calc_dphi, perc_diff\n",
    "from PyUtils.Utils_StatsAndFits import gaussian, fit_with_gaussian, iterative_fit_gaus\n",
    "from PyUtils.Utils_Collection_Helpers import weave_lists\n",
    "from d0_Utils.d0_cls import KinematicBin, KinBinOrganizer, GraphLine\n",
    "from d0_Utils.d0_fns import (make_binning_array, shift_binning_array, get_subset_mask, make_kinem_subplot, calc_x_err_bins, combine_cut_list)\n",
    "from d0_Utils.d0_dicts import color_dict, label_LaTeX_dict\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 10})    # Related to saving memory and opening plots.\n",
    "\n",
    "# pd.options.display.max_columns = 23\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "plt.style.use('cmsstyle_plot')\n",
    "# plt.style.use(\"grid_multiple_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 260 ms, sys: 6.63 s, total: 6.89 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "infile_path_MC_2016 = '/Users/Jake/Desktop/MC_2016.h5'\n",
    "infile_path_MC_2017 = '/Users/Jake/Desktop/Research/Higgs_Mass_Measurement/NTuples/MC/MC_2017.feather'\n",
    "infile_path_MC_2018 = '/Users/Jake/Desktop/Research/Higgs_Mass_Measurement/NTuples/MC/MC_2018.feather'\n",
    "\n",
    "# df_MC_2016 = pd.read_feather(infile_path_MC_2016)\n",
    "# df_MC_2017 = pd.read_feather(infile_path_MC_2017)\n",
    "# df_MC_2018 = pd.read_feather(infile_path_MC_2018)\n",
    "\n",
    "df_MC_2016 = pd.read_hdf(infile_path_MC_2016)\n",
    "# df_MC_2017 = pd.read_hdf(infile_path_MC_2017)\n",
    "# df_MC_2018 = pd.read_hdf(infile_path_MC_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KinBinOrganizer():\n",
    "    \"\"\"\n",
    "    Creates and organizes KinematicBin objects which all have exactly the same cuts, except for d0 cuts. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 n_evts_scan=1000, \n",
    "                 massZ_cut_ls=[60,120],\n",
    "                 eta_cut_ls=[0.0, 0.3], \n",
    "                 pT_cut_ls=[20, 60], \n",
    "                 d0_type='BS', \n",
    "                 dR_cut=0.05, \n",
    "                 use_ptotal_instead=False, \n",
    "                 verbose=True):\n",
    "        \"\"\"\n",
    "        These cuts will apply to all KinematicBin objects within this KinBinOrganizer container.\n",
    "        \"\"\"\n",
    "        self.df = df \n",
    "        self.n_evts_scan = n_evts_scan\n",
    "        self.massZ_cut_ls = massZ_cut_ls\n",
    "        self.eta_cut_ls = eta_cut_ls\n",
    "        self.pT_cut_ls = pT_cut_ls\n",
    "        self.d0_type = d0_type\n",
    "        self.dR_cut = dR_cut\n",
    "        self.use_ptotal_instead = use_ptotal_instead\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def make_kbin_ls_over_d0_range(self, d0_bin_limits):\n",
    "        \"\"\"\n",
    "        Make a list of KinematicBin objects, all with identical cuts EXCEPT d0q cuts. \n",
    "        \"\"\"\n",
    "        d0_bin_arr, d0_bin_width = make_binning_array(d0_bin_limits)\n",
    "        \n",
    "        if d0_bin_width < 0.0005:\n",
    "            err_msg = f\"WARNING: d0_bin_width ({d0_bin_width}) is too small (d0_bin_width < 0.0005).\\nStopping now.\"\n",
    "            raise ValueError(err_msg)    \n",
    "            \n",
    "        self.d0_bin_arr = d0_bin_arr\n",
    "        self.d0_bin_arr_shifted = shift_binning_array(d0_bin_arr)\n",
    "        \n",
    "        kbin_ls = []\n",
    "        for elem in range(len(d0_bin_arr)-1):\n",
    "            # Make a kbin for each d0 bin.\n",
    "            d0_this = d0_bin_arr[elem]\n",
    "            d0_next = d0_bin_arr[elem+1]\n",
    "\n",
    "            kb = KinematicBin(df_original=self.df, \n",
    "                              n_evts=self.n_evts_scan, \n",
    "                              massZ_cut_ls=self.massZ_cut_ls,\n",
    "                              eta_cut_ls=self.eta_cut_ls, \n",
    "                              pT_cut_ls=self.pT_cut_ls, \n",
    "                              d0q_cut_ls=[d0_this, d0_next],\n",
    "                              d0_type=self.d0_type,\n",
    "                              dR_cut=self.dR_cut,\n",
    "                              use_ptotal_instead=self.use_ptotal_instead, \n",
    "                              verbose=self.verbose)\n",
    "            kbin_ls.append(kb)\n",
    "            \n",
    "        self.kbin_ls = kbin_ls\n",
    "\n",
    "    def plot_dpToverpT_for_kbin_ls(self, kinem=\"delta_pToverpT1\", lep_selection_type='independent', \n",
    "                                   x_limits=[-0.3, 0.3], bin_limits=[-0.3, 0.3, 0.004], \n",
    "                                   run_over_only_n_evts=-1, \n",
    "                                   ax=None, y_max=-1, log_scale=False, \n",
    "                                   iter_gaus=(False, 3),\n",
    "                                   make_pdf=False, pdf_obj=None ):\n",
    "        \"\"\"\n",
    "        The main purpose of making these plots is to fill the stats_dict for each kbin.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        make_pdf : \n",
    "        \n",
    "        \"\"\"\n",
    "        for kb in self.kbin_ls:\n",
    "            kb.plot_1D_kinematics(kinem=kinem, lep_selection_type=lep_selection_type, \n",
    "                                  x_limits=x_limits, bin_limits=bin_limits, run_over_only_n_evts=run_over_only_n_evts, \n",
    "                                  ax=ax, x_label=\"\", y_label=\"\", title=\"\", y_max=y_max, log_scale=log_scale, \n",
    "                                  iter_gaus=iter_gaus)\n",
    "            if (make_pdf):\n",
    "                pdf_obj.savefig()\n",
    "            plt.close()\n",
    "        # All kbins have filled their stats_dict.\n",
    "            \n",
    "#     def get_dpToverpT_iter_gaus_fit_means(self, kinem):\n",
    "    def get_iter_gaus_fit_stats(self, kinem):\n",
    "        \"\"\"\"\"\"\n",
    "        # Get graph values.\n",
    "        self.hist_mean_ls     = []\n",
    "        self.hist_mean_err_ls = []\n",
    "        self.fit_mean_ls      = []\n",
    "        self.fit_mean_err_ls  = []\n",
    "        \n",
    "        for kb in self.kbin_ls:\n",
    "#             self.hist_mean_ls.append(kb.stats_dict['delta_pToverpT1']['hist_stats'][1])\n",
    "#             self.hist_mean_err_ls.append(kb.stats_dict['delta_pToverpT1']['hist_stats'][2])\n",
    "#             self.fit_mean_ls.append(kb.stats_dict['delta_pToverpT1']['fit_stats']['mean_ls'][-1])\n",
    "#             self.fit_mean_err_ls.append(kb.stats_dict['delta_pToverpT1']['fit_stats']['mean_err_ls'][-1])\n",
    "            self.hist_mean_ls.append(kb.stats_dict[kinem]['hist_stats'][1])\n",
    "            self.hist_mean_err_ls.append(kb.stats_dict[kinem]['hist_stats'][2])\n",
    "            self.fit_mean_ls.append(kb.stats_dict[kinem]['fit_stats']['mean_ls'][-1])\n",
    "            self.fit_mean_err_ls.append(kb.stats_dict[kinem]['fit_stats']['mean_err_ls'][-1])\n",
    "            \n",
    "class GraphLine():\n",
    "    \"\"\"\n",
    "    One of the lines drawn on a graph. Contains all the info that went into building this line. \n",
    "    \"\"\"\n",
    "    def __init__(self, x_vals, y_vals, y_err_vals=np.zeros(0)):\n",
    "        self.x_vals = x_vals\n",
    "        self.y_vals = y_vals\n",
    "#         self.x_err_vals = x_err_vals\n",
    "        self.y_err_vals = y_err_vals\n",
    "        \n",
    "    def draw_graph(self, kinem_x, kinem_y, x_label=\"\", y_label=\"\", binning_type=\"\", kbin_example=None, ax=None, count=1):\n",
    "        \"\"\"\n",
    "        Draws data points (values of: kinem_x, kinem_y) to an axes object. \n",
    "        In particular, used for making dpT/pT vs. d0q plots, but could probably be generalized.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        kinem_x : str\n",
    "            The full name of the kinematic variable plotted on the x-axis.\n",
    "            Should be a key in the label_LaTeX_dict.\n",
    "        kinem_y : str\n",
    "            The full name of the kinematic variable plotted on the y-axis.\n",
    "            Should be a key in the label_LaTeX_dict.\n",
    "        x_label : str\n",
    "            The x-axis label. If no x_label is given, then an automatic one \n",
    "            is generated based on kinem_x.\n",
    "        y_label : str\n",
    "            The y-axis label. If no y_label is given, then an automatic one \n",
    "            is generated based on kinem_y.\n",
    "        binning_type : str\n",
    "            Must be either 'eta' or 'pT'. Used for proper labeling of title and legend.\n",
    "        kbin_example : KinematicBin object\n",
    "            This KinematicBin contains all the cut information necessary for proper\n",
    "            legend and axes labeling.\n",
    "        ax : axes object\n",
    "            The axes on which to draw the graph. \n",
    "            If an axes is not provided, a default one is made.\n",
    "        count : int\n",
    "            A key to a dictionary of colors. \n",
    "            Values of the dict are color strings, like: 'black', 'red', etc. \n",
    "        \"\"\"\n",
    "        if binning_type not in [\"eta\", \"pT\"]:\n",
    "            raise ValueError(\"[ERROR] Wrong `binning_type` specified. Must be either 'pT' or 'eta'. Stopping now.\")\n",
    "            \n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(figsize=(12.8, 9.6))\n",
    "            \n",
    "#         #--- Check that things make sense: ---#\n",
    "#         # Example: If binning in eta, make sure each HistInfo object has identical pT_cuts as every other.\n",
    "#         wrong_eta_binning = (binning_type in 'eta') and len(set([(hist.pT_range[0], hist.pT_range[1]) for hist in entire_HistInfo_list])) != 1\n",
    "#         # Do same thing for binning in pT.\n",
    "#         wrong_pT_binning = (binning_type in 'pT') and len(set([(hist.eta_range[0], hist.eta_range[1]) for hist in entire_HistInfo_list])) != 1\n",
    "#         if (wrong_eta_binning or wrong_pT_binning):\n",
    "#             err_msg = f\"\\n\\nBinning type ({binning_type}) specified, \"\n",
    "#             err_msg += f\"but not all graphs share same {binning_type}_range. Stopping now.\"\n",
    "#             raise RuntimeError(err_msg)\n",
    "\n",
    "        al=1  # alpha=0 is transparent\n",
    "        elw=1  # error bar line width\n",
    "        ms=4  # marker size\n",
    "        ecolor=color_dict[count]\n",
    "        mec=color_dict[count]  # Marker edge color.\n",
    "        mfc=color_dict[count]  # Marker face color.\n",
    "        cs=1  # cap size\n",
    "        mew=0.7  # marker edge width\n",
    "\n",
    "        if len(x_label) == 0:\n",
    "            x_label = label_LaTeX_dict[kinem_x][\"independent_label\"]\n",
    "            unit_x = label_LaTeX_dict[kinem_x][\"units\"]\n",
    "            if len(unit_x) > 0:\n",
    "                x_label += \" [{}]\".format(unit_x)\n",
    "        if len(y_label) == 0:\n",
    "            y_label  = label_LaTeX_dict[kinem_y][\"independent_label\"]\n",
    "            y_label += \" (iterated Gaus fit mean)\"\n",
    "        title = label_LaTeX_dict[binning_type + \"1\"][\"independent_label\"] + \" Binning\"\n",
    "#         if binning_type == \"eta\":\n",
    "#             title = r\"$\\left| $\" + title + r\"$\\right| $\"\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        \n",
    "        # The \"x-errors\" are calculated automatically to be 1/2 the distance to the next data point. \n",
    "        low_x_err, high_x_err = calc_x_err_bins(self.x_vals)\n",
    "        \n",
    "        label_text = kbin_example.cut_dict[binning_type]\n",
    "        if (kbin_example.verbose):\n",
    "            print(\"Drawing graph, binning in {}:\".format(binning_type))\n",
    "            print(kbin_example.cut_dict[binning_type] + \"\\n\")\n",
    "        ax.errorbar(self.x_vals, self.y_vals, xerr=[low_x_err, high_x_err], yerr=self.y_err_vals, fmt='s', label=label_text,\n",
    "                #color=color_dict[count], \n",
    "                    elinewidth=elw, ms=ms, mec=mec, capsize=cs, mew=mew, mfc=mfc, ecolor=ecolor)\n",
    "        ax.legend(loc=\"lower right\", framealpha=al)#, fontsize=text_size_legend)\n",
    "        \n",
    "        # Don't show d0 cuts and the cuts of whatever binning type (like \"eta\") is being used.\n",
    "        tmp_dict = kbin_example.cut_dict.copy()\n",
    "        for key in list(kbin_example.cut_dict.keys()):\n",
    "            if (binning_type in key) or (\"d0\" in key):\n",
    "                del tmp_dict[key]\n",
    "                    \n",
    "        sorted_cut_ls = [value for (key, value) in sorted(tmp_dict.items())]\n",
    "        cut_str = combine_cut_list(sorted_cut_ls)\n",
    "        textbox_text = \"Selections:\\n\" + cut_str  # Don't show the d0 cut text. Luckily it is the first by alphabetical sorting. \n",
    "        \n",
    "        if count == 1:\n",
    "            ax.text(0.05, 0.85, textbox_text, horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "        \n",
    "    def do_linear_fit(self, ax=None):\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(figsize=(12.8,9.6)) \n",
    "        \n",
    "        # Do fit. \n",
    "        # Draw fit on axes.\n",
    "        # return optimized parameters\n",
    "        self.popt_linear = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make $p_T$ distributions in different $\\eta$ bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbin = KinematicBin(df_MC_2016, \n",
    "                    n_evts=10000, \n",
    "                    massZ_cut_ls=[60,120],\n",
    "                    eta_cut_ls=[0.0, 0.3], \n",
    "                    pT_cut_ls=[40, 50], \n",
    "                    d0q_cut_ls=[-0.005, 0.005],\n",
    "                    d0_type='BS',\n",
    "                    dR_cut=0.02,\n",
    "                    use_ptotal_instead=False, \n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Events found: 376075 (18.804% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$0.00 < \\left| \\eta^{\\mathrm{REC}} \\right| < 0.20$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 373297 (18.665% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$0.20 < \\left| \\eta^{\\mathrm{REC}} \\right| < 0.40$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 366476 (18.324% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$0.40 < \\left| \\eta^{\\mathrm{REC}} \\right| < 0.60$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 357455 (17.873% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$0.60 < \\left| \\eta^{\\mathrm{REC}} \\right| < 0.80$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 347495 (17.375% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$0.80 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.00$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 332410 (16.620% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.00 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.20$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 316752 (15.838% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.20 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.40$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 298112 (14.906% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.40 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.60$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 277357 (13.868% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.60 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.80$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 132792 (6.640% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.80 < \\left| \\eta^{\\mathrm{REC}} \\right| < 1.90$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 126100 (6.305% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$1.90 < \\left| \\eta^{\\mathrm{REC}} \\right| < 2.00$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 120409 (6.020% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$2.00 < \\left| \\eta^{\\mathrm{REC}} \\right| < 2.10$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 114209 (5.710% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$2.10 < \\left| \\eta^{\\mathrm{REC}} \\right| < 2.20$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 107874 (5.394% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$2.20 < \\left| \\eta^{\\mathrm{REC}} \\right| < 2.30$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "[INFO] Events found: 100806 (5.040% of total events scanned)\n",
      "using cuts: $-1.000 < d_{0}^{\\mathrm{BS}}*q(\\mu) < 1.000$\n",
      "$\\Delta R < 0.008$\n",
      "$2.30 < \\left| \\eta^{\\mathrm{REC}} \\right| < 2.40$\n",
      "$60.0 < m_{\\mu\\mu} < 120.0$ GeV\n",
      "$5 <$ $p_{T}^{\\mathrm{REC}}$ $< 1000$ GeV\n",
      "\n",
      "CPU times: user 7min 22s, sys: 6min 20s, total: 13min 43s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# f, ax = plt.subplots(figsize=(12.8,9.6))\n",
    "\n",
    "n_evts_scan = 2000000\n",
    "# n_evts_scan = 300000\n",
    "n_evts_keep = 1000000\n",
    "\n",
    "df = df_MC_2016\n",
    "d0_bin_limits = [-1, 1, 2]\n",
    "massZ_cut_ls=[60,120]\n",
    "pT_cut_ls=[5,1000]\n",
    "eta_cut_ls=[\n",
    "    [0.0, 0.2],\n",
    "    [0.2, 0.4],\n",
    "    [0.4, 0.6],\n",
    "    [0.6, 0.8],\n",
    "    [0.8, 1.0],\n",
    "    [1.0, 1.2],\n",
    "    [1.2, 1.4],\n",
    "    [1.4, 1.6],\n",
    "    [1.6, 1.8],\n",
    "    [1.8, 1.9],\n",
    "    [1.9, 2.0],\n",
    "    [2.0, 2.1],\n",
    "    [2.1, 2.2],\n",
    "    [2.2, 2.3],\n",
    "    [2.3, 2.4],\n",
    "]\n",
    "\n",
    "d0_type='BS'\n",
    "dR_cut=0.008\n",
    "use_ptotal_instead=False\n",
    "fit_iters = 3\n",
    "\n",
    "# outpath = \"/Users/Jake/Desktop/Research/Higgs_Mass_Measurement/d0_studies/pT_distributions_eta_binning/DY_MC_2016_3Mevts.pdf\"\n",
    "outpath = \"/Users/Jake/Desktop/Research/Higgs_Mass_Measurement/d0_studies/pT_distributions_eta_binning/test_09.pdf\"\n",
    "overwrite = True\n",
    "verbose = True\n",
    "\n",
    "#--- Automatons ---#\n",
    "dir_ = os.path.dirname(outpath)\n",
    "check_overwrite(outpath, overwrite)\n",
    "makeDirs(dir_) \n",
    "\n",
    "org_kbin_ls = []\n",
    "with PdfPages(outpath) as pdf:\n",
    "    for eta_reg_ls in eta_cut_ls: \n",
    "        org_kbin = KinBinOrganizer(df, n_evts_scan, massZ_cut_ls, eta_reg_ls, pT_cut_ls, d0_type, dR_cut, use_ptotal_instead, verbose)\n",
    "        org_kbin.make_kbin_ls_over_d0_range(d0_bin_limits)\n",
    "        org_kbin.plot_dpToverpT_for_kbin_ls(kinem=\"pT1\", lep_selection_type='independent', \n",
    "                                           x_limits=[-40, 250], bin_limits=[5, 200, 1], \n",
    "                                           run_over_only_n_evts=n_evts_keep, ax=None, y_max=-1, log_scale=False, \n",
    "                                           iter_gaus=(False, fit_iters),\n",
    "                                           make_pdf=True,\n",
    "                                           pdf_obj=pdf    # If make_pdf=True, must pass in pdf object here!\n",
    "                                           )  \n",
    "#         org_kbin.get_iter_gaus_fit_stats(\"pT1\")\n",
    "\n",
    "        org_kbin_ls.append(org_kbin)\n",
    "        plt.close(\"all\")\n",
    "    # Done looping over all eta regions.\n",
    "    \n",
    "    # Plot all graph lines on single axes. \n",
    "#     graph_ls = []\n",
    "#     f, ax = plt.subplots()\n",
    "#     for count,org_kb in enumerate(org_kbin_ls, 1):\n",
    "#         graph = GraphLine(org_kb.d0_bin_arr_shifted, org_kb.fit_mean_ls, org_kb.fit_mean_err_ls)\n",
    "#         graph.draw_graph(\"d0BSq1\", \"delta_pToverpT1\", binning_type=binning_type, kbin_example=org_kb.kbin_ls[0], ax=ax, count=count)\n",
    "#         # Note: if you want stats to show up on plot when doing draw_graph, then make sure count=1 at some point.\n",
    "#         graph_ls.append(graph)\n",
    "#     # Done looping over KinBinOrganizers.\n",
    "#     plt.tight_layout()\n",
    "#     pdf.savefig()\n",
    "#     plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_equal_hist_divisions(bin_edges, bin_vals, K):\n",
    "    \"\"\"\n",
    "    Return the bin edges which divide the histogram into divisions with equal entries. \n",
    "    \n",
    "    Algorithm example:\n",
    "        Want to split histogram of 100 entries up into 3 divisions. \n",
    "        Calculate hypothetical entries_per_division: 100/3 = 33.333.\n",
    "        Start from first bin and keep adding bin entries until you exceed entries_per_division. \n",
    "        Record this bin edge. \n",
    "        Do only 2 scans over the first two divisions.\n",
    "        Third division is found by deduction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bin_edges : list or array-like\n",
    "        \n",
    "    K : int\n",
    "        Number of divisions of area of hist, such that each division contains the same number of entries. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bin_div_ls : list\n",
    "        A list of the edges of each division along the x-axis. \n",
    "        The number of entries between divisions should have ~same number of entries, \n",
    "        (up to a User-specified window? Say 0.1% of true entries_per_div?)\n",
    "        \n",
    "    Notes:\n",
    "    Should be the case that: len(bin_entries) == len(bin_edges) - 1\n",
    "    \"\"\"\n",
    "    \n",
    "    entries_total = np.sum(bin_vals)\n",
    "    entries_per_div = entries_total / K\n",
    "    bin_div_ls = [bin_edges[0]]  \n",
    "    \n",
    "    print(\"[INFO] Performing {} divisions...\".format(K))\n",
    "\n",
    "    def compare_neighboring_bins(elem, current_sum, bin_arr):\n",
    "        \"\"\"Return the index of bin_edges which gives the smaller % difference.\"\"\"\n",
    "        \n",
    "        prev_sum =\n",
    "        prev_elem = elem - 1\n",
    "        \n",
    "        bin_arr\n",
    "        \n",
    "        return better_elem\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T COPY THIS INTO UTILS_PHYSICS! It's already there.\n",
    "\n",
    "def perc_diff(num, ref):\n",
    "    \"\"\"\n",
    "    Return the signed percent difference between two numbers, relative to one of them.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num : float\n",
    "        New number to which you want to compare to the reference number (ref).\n",
    "        If num < ref, then will return a negative percent difference.\n",
    "    ref : float\n",
    "        Reference number. Goes in the denominator.\n",
    "    \"\"\"\n",
    "    return (num - ref) / ref * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_equal_hist_divisions(bin_edges, bin_vals, K):\n",
    "    \"\"\"\n",
    "    Return the bin edges which divide the histogram into divisions with equal entries. \n",
    "    \n",
    "    Algorithm example:\n",
    "        Want to split histogram of 100 entries up into 3 divisions. \n",
    "        Calculate hypothetical entries_per_division: 100/3 = 33.333.\n",
    "        Start from first bin and keep adding bin entries until you exceed entries_per_division. \n",
    "        Record this bin edge. \n",
    "        Do only 2 scans over the first two divisions.\n",
    "        Third division is found by deduction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bin_edges : list or array-like\n",
    "        \n",
    "    K : int\n",
    "        Number of divisions of area of hist, such that each division contains the same number of entries. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bin_div_ls : list\n",
    "        A list of the edges of each division along the x-axis. \n",
    "        The number of entries between divisions should have ~same number of entries, \n",
    "        (up to a User-specified window? Say 0.1% of true entries_per_div?)\n",
    "        \n",
    "    Notes:\n",
    "    Should be the case that: len(bin_entries) == len(bin_edges) - 1\n",
    "    \"\"\"\n",
    "    def compare_neighboring_bins(bin_arr, elem_start, elem_end, true_sum):\n",
    "        \"\"\"\n",
    "        Returns the index of bin_edges which gives the smaller abs(% difference).\n",
    "        \"\"\"\n",
    "        # This element corresponds to the last bin which would not exceed true_sum.\n",
    "        prev_elem = elem_end - 1\n",
    "        \n",
    "        this_sum = np.sum(bin_arr[elem_start:elem_end+1])\n",
    "        prev_sum = np.sum(bin_arr[elem_start:prev_elem+1])\n",
    "        \n",
    "        this_perc_diff = perc_diff(this_sum, true_sum)\n",
    "        prev_perc_diff = perc_diff(prev_sum, true_sum)\n",
    "        \n",
    "        # Return element coresponding to smaller percent difference. \n",
    "        print(\"[INFO]    this_perc_diff ({}%) vs. prev_perc_diff ({}%)\".format(this_perc_diff, prev_perc_diff))\n",
    "        if abs(this_perc_diff) < abs(prev_perc_diff):\n",
    "            print(\"[INFO]    elem_end ({}) gave the lesser perc. diff: {}%\".format(elem_end, this_perc_diff))\n",
    "            return elem, this_sum, this_perc_diff\n",
    "        else:\n",
    "            print(\"[INFO]    prev_elem ({}) gave the lesser perc. diff: {}%\".format(prev_elem, prev_perc_diff))\n",
    "            return prev_elem, prev_sum, prev_perc_diff\n",
    "    \n",
    "    entries_total = np.sum(bin_vals)\n",
    "    entries_per_div = entries_total / K\n",
    "    bin_div_ls = [bin_edges[0]]  \n",
    "    \n",
    "    print(\"[INFO] Performing {} divisions...\".format(K))\n",
    "    last_div_elem = -1  # Don't touch! It needs to start at -1 because of indexing madness.\n",
    "    elem = 0\n",
    "    tmp_total_entries = 0\n",
    "    for count in range(1,K):\n",
    "        print(\"[INFO]  Division {}: Looking for {:.2f} entries\".format(count, entries_per_div))\n",
    "        \n",
    "        sum_entries = -1\n",
    "#         loop = 0\n",
    "        last_div_elem += 1\n",
    "        try:\n",
    "            while True:\n",
    "#                 loop += 1\n",
    "                # Find the element of the bin which exceeds the entries_per_div.\n",
    "                div_bin_vals = bin_vals[last_div_elem:elem+1]  # Have to add 1, since Python excludes right bound in slice.\n",
    "                sum_entries = np.sum(div_bin_vals)  \n",
    "#                 print(\"loop {}: sum_entries ({}) vs. entries_per_div ({})\".format(loop,sum_entries, entries_per_div))\n",
    "                if sum_entries >= entries_per_div:\n",
    "                    break\n",
    "                else:\n",
    "                    elem +=1\n",
    "        except IndexError:\n",
    "            print(\"\\n[!!!WARNING!!!] Could not find {:.2f} entries in division {}.\".format(entries_per_div, count))\n",
    "            print(\"  This is an artifact of the bin size. Try fewer than {} divisions.\".format(K))\n",
    "            return bin_div_ls\n",
    "\n",
    "#         print(\"Before comparing neighbors: elem={}, sum_entries={}\\ndiv_bin_vals={}\".format(elem,sum_entries,div_bin_vals))\n",
    "        # Now see if previous bin was a better decision, by taking the lesser percent difference. \n",
    "        elem, sum_entries, perc_diff_div = compare_neighboring_bins(bin_vals, last_div_elem, elem, entries_per_div)\n",
    "        # Found the best element, sum, and perc diff which correspond to this division bin. \n",
    "        print(\"[INFO]    Found {} entries ({:.4f}% than was searched for)\".format(sum_entries, perc_diff_div))\n",
    "#         print(\"[INFO]    last_div_elem before update: {}\".format(last_div_elem))\n",
    "        last_div_elem = elem\n",
    "#         print(\"[INFO]    last_div_elem AFTER update: {}\".format(last_div_elem))\n",
    "        bin_div = bin_edges[elem]\n",
    "        print(\"[INFO]    Dividing bin is: {}\\n\".format(bin_div))\n",
    "        bin_div_ls.append(bin_div)\n",
    "        # Start the next division at the element that we stopped at last. \n",
    "        # So don't change the counting of elem.\n",
    "        \n",
    "        tmp_total_entries += sum_entries\n",
    "    # All divisions, except last, performed successfully.\n",
    "    # Since last division isn't performed, append final bin.\n",
    "    bin_div_ls.append(bin_edges[-1])\n",
    "    \n",
    "    # Find number of entries remaining in last division. \n",
    "    excess_entries = np.sum(bin_vals[elem+1:])  # This slice will exclude the FIRST value (elem), oddly enough.\n",
    "    perc_diff_excess = perc_diff(excess_entries, entries_per_div)\n",
    "    print(\"[INFO]  Division {} was analyzed by deduction.\".format(K)) \n",
    "    print(\"[INFO]    Excess entries in this division: {} ({:.4f}% different from number searched for)\".format(excess_entries, perc_diff_excess))\n",
    "    print(\"[INFO]    Final bin division list is:\\n{}\".format(bin_div_ls))\n",
    "    tmp_total_entries += excess_entries\n",
    "    print(\"Total entries found: {}\".format(tmp_total_entries))\n",
    "    \n",
    "    return bin_div_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kb = org_kbin_ls[0].kbin_ls[0]\n",
    "\n",
    "bin_vals = kb.stats_dict['pT1']['bin_vals']\n",
    "bin_edges = kb.stats_dict['pT1']['bin_edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_ls_pT = [4,5,6,7,8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Performing 30 divisions...\n",
      "[INFO]  Division 1: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (19.79012878460944%) vs. prev_perc_diff (-3.309332909351083%)\n",
      "[INFO]    prev_elem (14) gave the lesser perc. diff: -3.309332909351083%\n",
      "[INFO]    Found 12771.0 entries (-3.3093% than was searched for)\n",
      "[INFO]    Dividing bin is: 19.0\n",
      "\n",
      "[INFO]  Division 2: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (17.67021751803817%) vs. prev_perc_diff (-18.777114043655033%)\n",
      "[INFO]    elem_end (18) gave the lesser perc. diff: 17.67021751803817%\n",
      "[INFO]    Found 15542.0 entries (17.6702% than was searched for)\n",
      "[INFO]    Dividing bin is: 23.0\n",
      "\n",
      "[INFO]  Division 3: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (45.191208425133055%) vs. prev_perc_diff (-9.108804445756773%)\n",
      "[INFO]    prev_elem (20) gave the lesser perc. diff: -9.108804445756773%\n",
      "[INFO]    Found 12005.0 entries (-9.1088% than was searched for)\n",
      "[INFO]    Dividing bin is: 25.0\n",
      "\n",
      "[INFO]  Division 4: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (15.709299596459743%) vs. prev_perc_diff (-45.69998712911017%)\n",
      "[INFO]    elem_end (22) gave the lesser perc. diff: 15.709299596459743%\n",
      "[INFO]    Found 15283.0 entries (15.7093% than was searched for)\n",
      "[INFO]    Dividing bin is: 27.0\n",
      "\n",
      "[INFO]  Division 5: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (35.71217661889295%) vs. prev_perc_diff (-34.744588547936495%)\n",
      "[INFO]    prev_elem (23) gave the lesser perc. diff: -34.744588547936495%\n",
      "[INFO]    Found 8619.0 entries (-34.7446% than was searched for)\n",
      "[INFO]    Dividing bin is: 28.0\n",
      "\n",
      "[INFO]  Division 6: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (45.25177731846367%) vs. prev_perc_diff (-29.543234833170555%)\n",
      "[INFO]    prev_elem (24) gave the lesser perc. diff: -29.543234833170555%\n",
      "[INFO]    Found 9306.0 entries (-29.5432% than was searched for)\n",
      "[INFO]    Dividing bin is: 29.0\n",
      "\n",
      "[INFO]  Division 7: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (53.26201346143654%) vs. prev_perc_diff (-25.20498784836578%)\n",
      "[INFO]    prev_elem (25) gave the lesser perc. diff: -25.20498784836578%\n",
      "[INFO]    Found 9879.0 entries (-25.2050% than was searched for)\n",
      "[INFO]    Dividing bin is: 30.0\n",
      "\n",
      "[INFO]  Division 8: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (62.27920745603076%) vs. prev_perc_diff (-21.532998690197683%)\n",
      "[INFO]    prev_elem (26) gave the lesser perc. diff: -21.532998690197683%\n",
      "[INFO]    Found 10364.0 entries (-21.5330% than was searched for)\n",
      "[INFO]    Dividing bin is: 31.0\n",
      "\n",
      "[INFO]  Division 9: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (70.38786805066587%) vs. prev_perc_diff (-16.187793853771552%)\n",
      "[INFO]    prev_elem (27) gave the lesser perc. diff: -16.187793853771552%\n",
      "[INFO]    Found 11070.0 entries (-16.1878% than was searched for)\n",
      "[INFO]    Dividing bin is: 32.0\n",
      "\n",
      "[INFO]  Division 10: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (77.08830187536435%) vs. prev_perc_diff (-13.424338095562574%)\n",
      "[INFO]    prev_elem (28) gave the lesser perc. diff: -13.424338095562574%\n",
      "[INFO]    Found 11435.0 entries (-13.4243% than was searched for)\n",
      "[INFO]    Dividing bin is: 33.0\n",
      "\n",
      "[INFO]  Division 11: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (83.82659125839447%) vs. prev_perc_diff (-9.487360029073072%)\n",
      "[INFO]    prev_elem (29) gave the lesser perc. diff: -9.487360029073072%\n",
      "[INFO]    Found 11955.0 entries (-9.4874% than was searched for)\n",
      "[INFO]    Dividing bin is: 34.0\n",
      "\n",
      "[INFO]  Division 12: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (88.93709163316448%) vs. prev_perc_diff (-6.686048712532464%)\n",
      "[INFO]    prev_elem (30) gave the lesser perc. diff: -6.686048712532464%\n",
      "[INFO]    Found 12325.0 entries (-6.6860% than was searched for)\n",
      "[INFO]    Dividing bin is: 35.0\n",
      "\n",
      "[INFO]  Division 13: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (94.44886092624981%) vs. prev_perc_diff (-4.376859654303044%)\n",
      "[INFO]    prev_elem (31) gave the lesser perc. diff: -4.376859654303044%\n",
      "[INFO]    Found 12630.0 entries (-4.3769% than was searched for)\n",
      "[INFO]    Dividing bin is: 36.0\n",
      "\n",
      "[INFO]  Division 14: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (99.725925757679%) vs. prev_perc_diff (-1.1742794194471602%)\n",
      "[INFO]    prev_elem (32) gave the lesser perc. diff: -1.1742794194471602%\n",
      "[INFO]    Found 13053.0 entries (-1.1743% than was searched for)\n",
      "[INFO]    Dividing bin is: 37.0\n",
      "\n",
      "[INFO]  Division 15: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (0.9002051771261547%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (33) gave the lesser perc. diff: 0.9002051771261547%\n",
      "[INFO]    Found 13327.0 entries (0.9002% than was searched for)\n",
      "[INFO]    Dividing bin is: 38.0\n",
      "\n",
      "[INFO]  Division 16: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (4.443485436966707%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (34) gave the lesser perc. diff: 4.443485436966707%\n",
      "[INFO]    Found 13795.0 entries (4.4435% than was searched for)\n",
      "[INFO]    Dividing bin is: 39.0\n",
      "\n",
      "[INFO]  Division 17: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (7.161514525177728%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (35) gave the lesser perc. diff: 7.161514525177728%\n",
      "[INFO]    Found 14154.0 entries (7.1615% than was searched for)\n",
      "[INFO]    Dividing bin is: 40.0\n",
      "\n",
      "[INFO]  Division 18: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (7.153943413511403%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (36) gave the lesser perc. diff: 7.153943413511403%\n",
      "[INFO]    Found 14153.0 entries (7.1539% than was searched for)\n",
      "[INFO]    Dividing bin is: 41.0\n",
      "\n",
      "[INFO]  Division 19: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (7.449216768498116%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (37) gave the lesser perc. diff: 7.449216768498116%\n",
      "[INFO]    Found 14192.0 entries (7.4492% than was searched for)\n",
      "[INFO]    Dividing bin is: 42.0\n",
      "\n",
      "[INFO]  Division 20: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (9.099719111757176%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (38) gave the lesser perc. diff: 9.099719111757176%\n",
      "[INFO]    Found 14410.0 entries (9.0997% than was searched for)\n",
      "[INFO]    Dividing bin is: 43.0\n",
      "\n",
      "[INFO]  Division 21: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (1.4226118821026463%) vs. prev_perc_diff (-100.0%)\n",
      "[INFO]    elem_end (39) gave the lesser perc. diff: 1.4226118821026463%\n",
      "[INFO]    Found 13396.0 entries (1.4226% than was searched for)\n",
      "[INFO]    Dividing bin is: 44.0\n",
      "\n",
      "[INFO]  Division 22: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (77.36086189535209%) vs. prev_perc_diff (-5.913795322567215%)\n",
      "[INFO]    prev_elem (40) gave the lesser perc. diff: -5.913795322567215%\n",
      "[INFO]    Found 12427.0 entries (-5.9138% than was searched for)\n",
      "[INFO]    Dividing bin is: 45.0\n",
      "\n",
      "[INFO]  Division 23: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (56.00275588464654%) vs. prev_perc_diff (-16.725342782080695%)\n",
      "[INFO]    prev_elem (41) gave the lesser perc. diff: -16.725342782080695%\n",
      "[INFO]    Found 10999.0 entries (-16.7253% than was searched for)\n",
      "[INFO]    Dividing bin is: 46.0\n",
      "\n",
      "[INFO]  Division 24: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (35.68946328389397%) vs. prev_perc_diff (-27.27190133327277%)\n",
      "[INFO]    prev_elem (42) gave the lesser perc. diff: -27.27190133327277%\n",
      "[INFO]    Found 9606.0 entries (-27.2719% than was searched for)\n",
      "[INFO]    Dividing bin is: 47.0\n",
      "\n",
      "[INFO]  Division 25: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (17.48851083804635%) vs. prev_perc_diff (-37.03863538283326%)\n",
      "[INFO]    elem_end (44) gave the lesser perc. diff: 17.48851083804635%\n",
      "[INFO]    Found 15518.0 entries (17.4885% than was searched for)\n",
      "[INFO]    Dividing bin is: 49.0\n",
      "\n",
      "[INFO]  Division 26: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (27.815507150914964%) vs. prev_perc_diff (-10.509460104027077%)\n",
      "[INFO]    prev_elem (46) gave the lesser perc. diff: -10.509460104027077%\n",
      "[INFO]    Found 11820.0 entries (-10.5095% than was searched for)\n",
      "[INFO]    Dividing bin is: 51.0\n",
      "\n",
      "[INFO]  Division 27: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (3.2169653470219%) vs. prev_perc_diff (-27.022054648284012%)\n",
      "[INFO]    elem_end (49) gave the lesser perc. diff: 3.2169653470219%\n",
      "[INFO]    Found 13633.0 entries (3.2170% than was searched for)\n",
      "[INFO]    Dividing bin is: 54.0\n",
      "\n",
      "[INFO]  Division 28: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (18.843739826318696%) vs. prev_perc_diff (-0.7275838311339281%)\n",
      "[INFO]    prev_elem (53) gave the lesser perc. diff: -0.7275838311339281%\n",
      "[INFO]    Found 13112.0 entries (-0.7276% than was searched for)\n",
      "[INFO]    Dividing bin is: 58.0\n",
      "\n",
      "[INFO]  Division 29: Looking for 13208.10 entries\n",
      "[INFO]    this_perc_diff (11.74203708330494%) vs. prev_perc_diff (-1.0909971911175744%)\n",
      "[INFO]    prev_elem (59) gave the lesser perc. diff: -1.0909971911175744%\n",
      "[INFO]    Found 13064.0 entries (-1.0910% than was searched for)\n",
      "[INFO]    Dividing bin is: 64.0\n",
      "\n",
      "[INFO]  Division 30 was analyzed by deduction.\n",
      "[INFO]    Excess entries in this division: 32400.0 (145.3040% different from number searched for)\n",
      "[INFO]    Final bin division list is:\n",
      "[5.0, 19.0, 23.0, 25.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 49.0, 51.0, 54.0, 58.0, 64.0, 200.0]\n",
      "Total entries found: 396243.0\n"
     ]
    }
   ],
   "source": [
    "bins_pT = find_equal_hist_divisions(bin_edges, bin_vals, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                      \n",
    "\n",
    "    \n",
    "    pdf_name  = f\"{year}_{sample}_{bspv}__\"\n",
    "    title_str_pT_min = f\"0{pT_min}\" if pT_min < 10 else f\"{pT_min}\"  # For plot-ordering purposes.\n",
    "    # Example of Python magic: auto-concatenation of strings.\n",
    "    pdf_name += (f\"{title_str_pT_min}_pT_{pT_max}\"\n",
    "                 f\"__{eta_min}_eta_{eta_max}\"\n",
    "                 f\"__{d0_min:.3f}_to_{d0_max:.3f}_increm_{d0_bin_width:.3f}\"\n",
    "                 f\"__wrt_{wrt}\")\n",
    "    pdf_name = make_str_title_friendly(pdf_name) + \".pdf\"\n",
    "    \n",
    "    outfile = os.path.join(outfile_path, pdf_name)\n",
    "    if not os.path.exists(outfile_path):\n",
    "        os.makedirs(outfile_path)\n",
    "    if os.path.exists(outfile) and not (overwrite):\n",
    "        print(f\"Skipping {outfile} since it already exists.\\nTo write over the file then set overwrite=True.\\n\")\n",
    "        return\n",
    "        \n",
    "    status = f\"Running over: {year} {sample} {bspv}, pT_range={pT_cut_ls}, eta_range={eta_cut_ls}, wrt {wrt}\"\n",
    "    print(status)\n",
    "\n",
    "            # Store info of this plot in a HistInfo object. \n",
    "            this_hist = HistInfo()            \n",
    "            this_hist.year = year\n",
    "            this_hist.sample = sample\n",
    "            this_hist.bspv = bspv\n",
    "            this_hist.d0_bin_window = [this_d0_bin, next_d0_bin]\n",
    "            this_hist.x_axis_bounds_list = deltapT_range_ls[0:2] # 2-element list\n",
    "            this_hist.eta_range = eta_cut_ls\n",
    "            this_hist.pT_range = pT_cut_ls\n",
    "            this_hist.massZ_cut = massZ_min\n",
    "            this_hist.n_entries = n_entries\n",
    "            this_hist.hist_mean = mean\n",
    "            this_hist.hist_mean_err = mean_err\n",
    "            this_hist.hist_stdev = stdev  # Spread of the data.\n",
    "            this_hist.hist_stdev_err = stdev_err\n",
    "            \n",
    "            graph_info_ls.append(this_hist)\n",
    "            \n",
    "        return graph_info_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grids of 2D plots.\n",
    "\n",
    "#### FIXME: \n",
    "- [ ] Use np.arrays to contain kbins for easy reshaping?\n",
    "- [ ] Eventually merge into make_grid_of_2D_plots_FIXME.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_evts = 10000\n",
    "\n",
    "eta_bin_BARREL  = [0.0, 0.3]\n",
    "eta_bin_OVERLAP = [0.8, 1.1]\n",
    "eta_bin_ENDCAP  = [2.1, 2.4]\n",
    "\n",
    "\n",
    "pT_bin_LOW1 = [5, 7]\n",
    "pT_bin_LOW2 = [7, 10]\n",
    "pT_bin_LOW3 = [10, 15]\n",
    "pT_bin_LOW4 = [15, 20]\n",
    "pT_bin_LOW5 = [20, 25]\n",
    "pT_bin_LOW6 = [25, 30]\n",
    "\n",
    "pT_bin_MED1 = [30, 35]\n",
    "pT_bin_MED2 = [35, 40]\n",
    "pT_bin_MED3 = [40, 45]\n",
    "pT_bin_MED4 = [45, 50]\n",
    "pT_bin_MED5 = [50, 55]\n",
    "pT_bin_MED6 = [55, 60]\n",
    "\n",
    "pT_bin_HIGH1 = [60, 65]\n",
    "pT_bin_HIGH2 = [65, 70]\n",
    "pT_bin_HIGH3 = [70, 75]\n",
    "pT_bin_HIGH4 = [75, 80]\n",
    "pT_bin_HIGH5 = [80, 90]\n",
    "pT_bin_HIGH6 = [90, 100]\n",
    "\n",
    "#--------------#\n",
    "#--- Barrel ---#\n",
    "#--------------#\n",
    "# Low pT.\n",
    "kbin_eta_BARREL_pT_bin_LOW1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW1, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_LOW2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW2, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_LOW3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW3, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_LOW4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW4, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_LOW5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW5, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_LOW6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_LOW6, dR_cut=0.02)\n",
    "\n",
    "# Med pT.\n",
    "kbin_eta_BARREL_pT_bin_MED1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED1, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_MED2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED2, dR_cut=0.02)\n",
    "kbin_eta_BARREL_pT_bin_MED3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED3, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_MED4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED4, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_MED5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED5, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_MED6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_MED6, dR_cut=0.02)\n",
    "\n",
    "# # High pT.\n",
    "# kbin_eta_BARREL_pT_bin_HIGH1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH1, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_HIGH2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH2, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_HIGH3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH3, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_HIGH4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH4, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_HIGH5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH5, dR_cut=0.02)\n",
    "# kbin_eta_BARREL_pT_bin_HIGH6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_BARREL, pT_cut_ls=pT_bin_HIGH6, dR_cut=0.02)\n",
    "\n",
    "\n",
    "# #---------------#\n",
    "# #--- Overlap ---#\n",
    "# #---------------#\n",
    "# # Low pT.\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW1, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW2, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW3, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW4, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW5, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_LOW6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_LOW6, dR_cut=0.02)\n",
    "\n",
    "# # Med pT.\n",
    "# kbin_eta_OVERLAP_pT_bin_MED1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED1, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_MED2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED2, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_MED3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED3, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_MED4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED4, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_MED5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED5, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_MED6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_MED6, dR_cut=0.02)\n",
    "\n",
    "# # High pT.\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH1, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH2, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH3, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH4, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH5, dR_cut=0.02)\n",
    "# kbin_eta_OVERLAP_pT_bin_HIGH6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_OVERLAP, pT_cut_ls=pT_bin_HIGH6, dR_cut=0.02)\n",
    "\n",
    "# #---------------#\n",
    "# #--- Endcap ---#\n",
    "# #---------------#\n",
    "# # Low pT.\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW1, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW2, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW3, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW4, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW5, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_LOW6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_LOW6, dR_cut=0.02)\n",
    "\n",
    "# # Med pT.\n",
    "# kbin_eta_ENDCAP_pT_bin_MED1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED1, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_MED2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED2, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_MED3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED3, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_MED4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED4, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_MED5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED5, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_MED6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_MED6, dR_cut=0.02)\n",
    "\n",
    "# # High pT.\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH1 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH1, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH2 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH2, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH3 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH3, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH4 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH4, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH5 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH5, dR_cut=0.02)\n",
    "# kbin_eta_ENDCAP_pT_bin_HIGH6 = KinemBinnedEtaPt(df_MC_2016, n_evts=n_evts, eta_cut_ls=eta_bin_ENDCAP, pT_cut_ls=pT_bin_HIGH6, dR_cut=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(org_kbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in org_kbin.__dict__.items():\n",
    "    print(\"key is:\", key, \"   value is:\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from d0_Utils.d0_fns import calc_x_err_bins\n",
    "from d0_Utils.d0_dicts import color_dict, label_LaTeX_dict\n",
    "\n",
    "class GraphLine():\n",
    "    \"\"\"\n",
    "    One of the lines drawn on a graph. Contains all the info that went into building this line. \n",
    "    \"\"\"\n",
    "    def __init__(self, x_vals, y_vals, y_err_vals=np.zeros(0)):\n",
    "        self.x_vals = x_vals\n",
    "        self.y_vals = y_vals\n",
    "#         self.x_err_vals = x_err_vals\n",
    "        self.y_err_vals = y_err_vals\n",
    "        \n",
    "    def draw_graph(self, kinem_x, kinem_y, x_label=\"\", y_label=\"\", binning_type=\"\", kbin_example=None, ax=None):\n",
    "        \"\"\"\n",
    "        kinem_x : str\n",
    "            The full name of the kinematic variable plotted on the x-axis.\n",
    "            Should be a key in the label_LaTeX_dict.\n",
    "        kinem_y : str\n",
    "            The full name of the kinematic variable plotted on the y-axis.\n",
    "            Should be a key in the label_LaTeX_dict.\n",
    "        \"\"\"\n",
    "        if binning_type not in [\"eta\", \"pT\"]:\n",
    "            raise ValueError(\"[ERROR] Wrong `binning_type` specified. Must be either 'pT' or 'eta'. Stopping now.\")\n",
    "            \n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(figsize=(12.8, 9.6))\n",
    "            \n",
    "#         #--- Check that things make sense: ---#\n",
    "#         # Example: If binning in eta, make sure each HistInfo object has identical pT_cuts as every other.\n",
    "#         wrong_eta_binning = (binning_type in 'eta') and len(set([(hist.pT_range[0], hist.pT_range[1]) for hist in entire_HistInfo_list])) != 1\n",
    "#         # Do same thing for binning in pT.\n",
    "#         wrong_pT_binning = (binning_type in 'pT') and len(set([(hist.eta_range[0], hist.eta_range[1]) for hist in entire_HistInfo_list])) != 1\n",
    "#         if (wrong_eta_binning or wrong_pT_binning):\n",
    "#             err_msg = f\"\\n\\nBinning type ({binning_type}) specified, \"\n",
    "#             err_msg += f\"but not all graphs share same {binning_type}_range. Stopping now.\"\n",
    "#             raise RuntimeError(err_msg)\n",
    "        al=1  # alpha=0 is transparent\n",
    "        elw=1  # error bar line width\n",
    "        ecolor='k'\n",
    "        ms=4  # marker size\n",
    "        mec='k'  # marker edge color\n",
    "        cs=1  # cap size\n",
    "        mew=0.7  # marker edge width\n",
    "\n",
    "        if len(x_label) == 0:\n",
    "            x_label = label_LaTeX_dict[kinem_x][\"independent_label\"]\n",
    "        if len(y_label) == 0:\n",
    "            y_label  = label_LaTeX_dict[kinem_y][\"independent_label\"]\n",
    "            y_label += \" (iterated Gaus fit mean)\"\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        \n",
    "        # The \"x-errors\" are calculated automatically to be 1/2 the distance to the next data point. \n",
    "        low_x_err, high_x_err = calc_x_err_bins(self.x_vals)\n",
    "        \n",
    "        label_text = kbin_example.cut_dict[binning_type]\n",
    "        ax.errorbar(self.x_vals, self.y_vals, xerr=[low_x_err, high_x_err], yerr=self.y_err_vals, fmt='.', label=label_text,\n",
    "                #color=color_dict[count], \n",
    "                    elinewidth=elw, ms=ms, markeredgecolor=mec, capsize=cs, mew=mew, ecolor=ecolor)\n",
    "        ax.legend(loc=\"lower right\", framealpha=al)#, fontsize=text_size_legend)\n",
    "        \n",
    "        # Don't show d0 cuts and the cuts of whatever binning type (like \"eta\") is being used.\n",
    "        tmp_dict = kbin_example.cut_dict.copy()\n",
    "        for key in list(kbin_example.cut_dict.keys()):\n",
    "            if (binning_type in key) or (\"d0\" in key):\n",
    "                del tmp_dict[key]\n",
    "                    \n",
    "        sorted_cut_ls = [value for (key, value) in sorted(tmp_dict.items())]\n",
    "        cut_str = combine_cut_list(sorted_cut_ls)\n",
    "        textbox_text = cut_str  # Don't show the d0 cut text. Luckily it is the first by alphabetical sorting. \n",
    "        ax.text(0.025, 0.87, textbox_text, horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "        \n",
    "    def do_linear_fit(self, ax=None):\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(figsize=(12.8,9.6)) \n",
    "        \n",
    "        # Do fit. \n",
    "        # Draw fit on axes.\n",
    "        # return optimized parameters\n",
    "        self.popt_linear = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescue_code(function):\n",
    "    import inspect\n",
    "    get_ipython().set_next_input(\"\".join(inspect.getsourcelines(function)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescue_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KinBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evts = 1000\n",
    "\n",
    "# dataframe = pd.read_hdf('/Users/Jake/Desktop/MC_2016.h5')\n",
    "\n",
    "\n",
    "massZ_cut_ls = [60,120]\n",
    "d0q_cut_ls = [-0.01, 0.01]\n",
    "d0_type = \"BS\"\n",
    "dR_cut = 0.02\n",
    "use_ptotal_instead = False\n",
    "verbose = False\n",
    "\n",
    "eta_regions = [\n",
    "    [0.0, 0.3],\n",
    "    [0.8, 1.1],\n",
    "#     [2.1, 2.4]\n",
    "]\n",
    "\n",
    "# You should make there's always 18 different regions.\n",
    "pT_regions = [\n",
    "    [5, 7]  ,\n",
    "    [7, 10] ,\n",
    "    [10, 15],\n",
    "    [15, 20],\n",
    "    [20, 25],\n",
    "#     [25, 30],\n",
    "#     [30, 35],\n",
    "#     [35, 40],\n",
    "#     [40, 45],\n",
    "#     [45, 50],\n",
    "#     [50, 55],\n",
    "#     [55, 60],\n",
    "#     [60, 65],\n",
    "#     [65, 70],\n",
    "#     [70, 75],\n",
    "#     [75, 80],\n",
    "#     [80, 90],\n",
    "#     [90, 100]\n",
    "]\n",
    "\n",
    "all_kbin_ls = []\n",
    "for eta_reg in eta_regions:\n",
    "    for pT_reg in pT_regions:\n",
    "        all_kbin_ls.append( KinematicBin(df_MC_2016, n_evts, massZ_cut_ls, eta_reg, pT_reg, d0q_cut_ls, \n",
    "                                         d0_type, dR_cut, use_ptotal_instead, verbose) \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb1 = all_kbin_ls[0]\n",
    "kb2 = all_kbin_ls[1]\n",
    "kb3 = all_kbin_ls[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First edition $dp_T/p_T^2$ vs. $d_0*q$ plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(*graph_tuple, binning_type='eta', verbose=False, save_plots=True, outpath='/Users/Jake/Desktop/'):\n",
    "    \"\"\"\n",
    "    Make one deltapT vs. d0*charge plot, with as many graphs displayed as len(graph_tuple).\n",
    "    graph_tuple contains many lists (graph_lsX) of histograms (HistInfo).\n",
    "    \n",
    "    graph_tuple = (\n",
    "        graph_ls1,  # Each hist in this graph_ls all have identical cuts, but are made over different d0 bins.\n",
    "        graph_ls2,  # This graph_ls2 may have slightly different cuts than graph_ls1.\n",
    "        ...,\n",
    "    )\n",
    "    \n",
    "    #--- Example ---#\n",
    "    graph_ls1 = [HistInfo1, HistInfo2, ...]  # This list will generate 1 deltapT_vs_d0charge graph. \n",
    "    graph_ls2 = [HistInfo1, HistInfo2, ...]  # This list will generate another graph, but may have different cuts. \n",
    "\n",
    "    If binning_type is 'eta', then each graph_ls in graph_tuple should have the same pT cuts.\n",
    "        This way, we can view different eta ranges while making sure pT cuts are all the same. \n",
    "    If binning_type is 'pT', then each graph_ls in graph_tuple should have the same eta cuts. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    graph_ls contains all the correct graph info to make a plot. \n",
    "    \"\"\"    \n",
    "\n",
    "        \n",
    "    text_size_legend = 6\n",
    "    text_size_ax_labels = 12\n",
    "    text_size_tick_labels = 8\n",
    "    text_size_title = 12\n",
    "\n",
    "\n",
    "    # If binning in eta, then each graph should the same pT cuts. \n",
    "    if binning_type in 'eta':\n",
    "        title_str += f'{example_graph.pT_range[0]}<' + r'$p_T$' + f'<{example_graph.pT_range[1]} GeV'\n",
    "    elif binning_type in 'pT':\n",
    "        title_str += f'{example_graph.eta_range[0]}<' + r'$\\left| \\eta \\right|$' + f'<{example_graph.eta_range[1]}'\n",
    "    ax.set_title(title_str)\n",
    "\n",
    "    x_min = min([gr.d0_bin_window[0] for gr in example_graph_ls])\n",
    "    x_max = max([gr.d0_bin_window[1] for gr in example_graph_ls])\n",
    "    bin_edge_left = example_graph.d0_bin_window[0]\n",
    "    bin_edge_right = example_graph.d0_bin_window[1]\n",
    "    x_bin_width = abs(bin_edge_right - bin_edge_left)\n",
    "\n",
    "    # ax.set_xlim([x_min*x_axis_scale, x_max*x_axis_scale])\n",
    "    ax.set_xlim([-0.012, 0.012])\n",
    "    ax.set_ylim([-0.005, 0.005])\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0), useMathText=True)\n",
    "    \n",
    "    # Gridlines.\n",
    "    ax.grid(which='major',color='k', ls=':')\n",
    "\n",
    "    x_bin_arr = np.arange(x_min, x_max+0.5*x_bin_width, x_bin_width)  # Includes all bin edges: very first to very last.\n",
    "    x_n_bins = calc_num_bins(x_min, x_max, x_bin_width)\n",
    "\n",
    "    # Calculate %diff for ratio plot.\n",
    "    # acc_ZD_arr = np.array(acc_ZD, dtype=float)\n",
    "    # acc_ALP_arr = np.array(acc_ALP, dtype=float)\n",
    "    # acc_perc_diff_arr = (acc_ALP_arr - acc_ZD_arr) / acc_ZD_arr\n",
    "\n",
    "    # Calculate errors on %diff.\n",
    "    # acc_perc_diff_err_arr = getUncertOfFractionBinomial(acc_ALP_arr, acc_ZD_arr)\n",
    "\n",
    "    # Plot the data.\n",
    "    for count, gr_ls in enumerate(graph_tuple, 1):\n",
    "        example_gr = gr_ls[0]\n",
    "        y_vals = [gr.hist_mean for gr in gr_ls]\n",
    "        y_vals_err = [gr.hist_mean_err for gr in gr_ls]\n",
    "        if (verbose): \n",
    "            print(f'y_vals for graph_ls {count}:\\n{y_vals}\\n')\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "        plotname  = (f'deltapT_vs_d0{example_graph.bspv}timescharge_{example_graph.sample}{example_graph.year}_'\n",
    "                     f'{binning_type}binning__')\n",
    "        if binning_type in 'pT':\n",
    "            plotname += f'{example_graph.eta_range[0]}_eta_{example_graph.eta_range[1]}'\n",
    "        elif binning_type in 'eta':\n",
    "            plotname += f'{example_graph.pT_range[0]}_pT_{example_graph.pT_range[1]}'\n",
    "        plotname = make_str_title_friendly(plotname)\n",
    "        \n",
    "        fullpath = os.path.join(outpath, plotname)\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        plt.savefig(fullpath + '.pdf')\n",
    "        plt.savefig(fullpath + '.png')\n",
    "        print(\"Plot saved at:\\n\", fullpath)\n",
    "    \n",
    "\n",
    "# def make_kinem_comparison_plot(df, year, sample, \n",
    "# \n",
    "#     \n",
    "#     pdf_name  = f\"{year}_{sample}_\"\n",
    "#     title_str_pT_min = f\"0{pT_min}\" if pT_min < 10 else f\"{pT_min}\"  # For plot-ordering purposes.\n",
    "#     # Example of Python magic: auto-concatenation of strings.\n",
    "#     pdf_name += (f\"{kinem_gen}_vs_{kinem_rec}__{bspv}\"\n",
    "#                  f\"__{title_str_pT_min}_pT_{pT_max}\"\n",
    "#                  f\"__{eta_min_abs}_abs_eta_{eta_max_abs}\"\n",
    "#                  f\"__{d0_min:.3f}_to_{d0_max:.3f}_increm_{d0_bin_width:.3f}\")\n",
    "#                 #  f\"__wrt_{wrt}\")\n",
    "#     pdf_name = make_str_title_friendly(pdf_name) + \".pdf\"\n",
    "#     \n",
    "#     outfile = os.path.join(outfile_path, pdf_name)\n",
    "#     if not os.path.exists(outfile_path):\n",
    "#         os.makedirs(outfile_path)\n",
    "#     if os.path.exists(outfile) and not (overwrite):\n",
    "#         print(f\"Skipping {outfile} since it already exists.\\nTo write over the file then set overwrite=True.\\n\")\n",
    "#         return\n",
    "#         \n",
    "#     status = f\"Running over: {year} {sample} {bspv}, pT_range={pT_cut_ls}, eta_range={eta_cut_ls}, wrt {wrt}\"\n",
    "#     print(status)\n",
    "# \n",
    "# \n",
    "#         for k in range(len(d0_bin_arr)-1):\n",
    "#             this_d0_bin = d0_bin_arr[k]\n",
    "#             next_d0_bin = d0_bin_arr[k+1]\n",
    "#             if bspv in 'BS':\n",
    "#                 mask_d0BSxcharge = (this_d0_bin < d0BSxcharge_ser) & (d0BSxcharge_ser < next_d0_bin)\n",
    "#                 # mask_d0BS2xcharge = (this_d0_bin < d0BS2xcharge_ser) & (d0BS2xcharge_ser < next_d0_bin)\n",
    "#             elif bspv in 'PV':\n",
    "#                 mask_d0PVxcharge = (this_d0_bin < d0PVxcharge_ser) & (d0PVxcharge_ser < next_d0_bin)\n",
    "#                 # mask_d0PV2xcharge = (this_d0_bin < d0PV2xcharge_ser) & (d0PV2xcharge_ser < next_d0_bin)\n",
    "# \n",
    "#                 \n",
    "#  \n",
    "#             # Store info of this plot in HistInfo objects. \n",
    "#             hist_gen = HistInfo()\n",
    "#             hist_rec = HistInfo()            \n",
    "#             hist_gen.year = year\n",
    "#             hist_rec.year = year\n",
    "#             hist_gen.sample = sample \n",
    "#             hist_rec.sample = sample\n",
    "#             hist_gen.bspv = bspv \n",
    "#             hist_rec.bspv = bspv\n",
    "#             hist_gen.d0_bin_window = [this_d0_bin, next_d0_bin] \n",
    "#             hist_rec.d0_bin_window = [this_d0_bin, next_d0_bin]\n",
    "#             hist_gen.x_axis_bounds_list = x_range_ls[0:2] # 2-element list \n",
    "#             hist_rec.x_axis_bounds_list = x_range_ls[0:2] # 2-element list\n",
    "#             hist_gen.eta_range = eta_cut_ls \n",
    "#             hist_rec.eta_range = eta_cut_ls\n",
    "#             hist_gen.pT_range = pT_cut_ls\n",
    "#             hist_rec.pT_range = pT_cut_ls\n",
    "#             hist_gen.massZ_cut = massZ_min\n",
    "#             hist_rec.massZ_cut = massZ_min\n",
    "#             hist_gen.n_entries = n_entries_gen\n",
    "#             hist_rec.n_entries = n_entries_rec\n",
    "#             hist_gen.hist_mean = mean_gen\n",
    "#             hist_rec.hist_mean = mean_rec\n",
    "#             hist_gen.hist_mean_err = mean_err_gen\n",
    "#             hist_rec.hist_mean_err = mean_err_rec\n",
    "#             hist_gen.hist_stdev = stdev_gen\n",
    "#             hist_rec.hist_stdev = stdev_rec  # Spread of the data.\n",
    "#             hist_gen.hist_stdev_err = stdev_err_gen\n",
    "#             hist_rec.hist_stdev_err = stdev_err_rec\n",
    "#             \n",
    "#             graph_info_gen_ls.append(hist_gen)\n",
    "#             graph_info_rec_ls.append(hist_rec)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "fig = plt.figure(figsize=(25.6,19.2))\n",
    "ax = plt.subplot(221)\n",
    "kbin.plot_1D_kinematics(kinem=\"delta_pToverpT1\", lep_selection_type='independent', x_limits=[-0.5, 0.5], bin_limits=[-0.5, 0.5, 0.004], run_over_only_n_evts=-1, ax=ax, y_max=-1, log_scale=False, iter_gaus=(True, 3))\n",
    "ax = plt.subplot(222)\n",
    "kbin.plot_1D_kinematics(kinem=\"delta_pToverRecpT1\", lep_selection_type='independent', x_limits=[-0.5, 0.5], bin_limits=[-0.5, 0.5, 0.004], run_over_only_n_evts=-1, ax=ax, y_max=-1, log_scale=False, iter_gaus=(False, 3))\n",
    "ax = plt.subplot(223)\n",
    "kbin.plot_1D_kinematics(kinem=\"d0BSq1\", lep_selection_type='independent', x_limits=[-0.05, 0.05], bin_limits=[-0.02, 0.02, 0.0004], run_over_only_n_evts=n_evts_keep, ax=ax, y_max=-1, log_scale=False, iter_gaus=(True, 4))\n",
    "ax = plt.subplot(224)\n",
    "kbin.plot_1D_kinematics(kinem=\"d0BSq2\", lep_selection_type='independent', x_limits=[-0.05, 0.05], bin_limits=[-0.02, 0.02, 0.0004], run_over_only_n_evts=n_evts_keep, ax=ax, y_max=-1, log_scale=False, iter_gaus=(False, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinematics subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbin.plot_1D_kinematics(kinem=\"d0BSq1\", lep_selection_type='independent', x_limits=[-0.02, 0.02], bin_limits=[-0.008, 0.008, 0.0002], run_over_only_n_evts=n_evts_keep, ax=None, y_max=-1, log_scale=False, iter_gaus=(True, 4))\n",
    "kbin.plot_1D_kinematics(kinem=\"delta_pToverpT1\", lep_selection_type='independent', x_limits=[-0.3, 0.3], bin_limits=[-0.3, 0.3, 0.004], run_over_only_n_evts=n_evts_keep, ax=None, y_max=-1, log_scale=False, iter_gaus=(True, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbin.cut_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in play_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_dict = {'a':1, 'b':2, 'c':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_test.draw_graph(\"d0BSq1\",\"delta_pToverpT1\",kbin_example=kbin_ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbin.stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_test.draw_graph(\"d0BSq1\",\"delta_pToverpT1\",kbin_example=kbin_ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_mean = kbin.stats_dict['delta_pToverpT1']['hist_stats'][1]\n",
    "# hist_mean_err = kbin.stats_dict['delta_pToverpT1']['hist_stats'][2]\n",
    "# fit_mean = kbin.stats_dict['delta_pToverpT1']['fit_stats']['mean_ls'][-1]\n",
    "# fit_mean_err = kbin.stats_dict['delta_pToverpT1']['fit_stats']['mean_err_ls'][-1]\n",
    "\n",
    "d0_bin_arr, d0_bin_width = make_binning_array(d0_bin_limits)\n",
    "d0_bin_arr_shifted = shift_binning_array(d0_bin_arr)\n",
    "\n",
    "if d0_bin_width < 0.0005:\n",
    "    err_msg = f\"WARNING: d0_bin_width ({d0_bin_width}) is too small (d0_bin_width < 0.0005).\\nStopping now.\"\n",
    "    raise ValueError(err_msg)    \n",
    "\n",
    "# Make list of kinematic bins.\n",
    "kbin_ls = []\n",
    "with PdfPages(outpath) as pdf:\n",
    "    for elem in range(len(d0_bin_arr)-1):\n",
    "        # Make a kbin for each d0 bin.\n",
    "        d0_this = d0_bin_arr[elem]\n",
    "        d0_next = d0_bin_arr[elem+1]\n",
    "\n",
    "        kbin = KinematicBin(df_MC_2016, \n",
    "                            n_evts=n_evts_scan, \n",
    "                            massZ_cut_ls=[60,120],\n",
    "                            eta_cut_ls=[0.0, 0.3], \n",
    "                            pT_cut_ls=[40, 50], \n",
    "                            d0q_cut_ls=[d0_this, d0_next],\n",
    "                            d0_type='BS',\n",
    "                            dR_cut=0.02,\n",
    "                            use_ptotal_instead=False, \n",
    "                            verbose=True)\n",
    "        kbin.plot_1D_kinematics(kinem=\"delta_pToverpT1\", lep_selection_type='independent', x_limits=[-0.3, 0.3], bin_limits=[-0.3, 0.3, 0.004], run_over_only_n_evts=n_evts_keep, ax=None, y_max=-1, log_scale=False, iter_gaus=(True, 4))\n",
    "        kbin_ls.append(kbin)\n",
    "        \n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "# Get graph values.\n",
    "hist_mean_ls     = []\n",
    "hist_mean_err_ls = []\n",
    "fit_mean_ls      = []\n",
    "fit_mean_err_ls  = []\n",
    "for kb in kbin_ls:\n",
    "    hist_mean_ls.append(kb.stats_dict['delta_pToverpT1']['hist_stats'][1])\n",
    "    hist_mean_err_ls.append(kb.stats_dict['delta_pToverpT1']['hist_stats'][2])\n",
    "    fit_mean_ls.append(kb.stats_dict['delta_pToverpT1']['fit_stats']['mean_ls'][-1])\n",
    "    fit_mean_err_ls.append(kb.stats_dict['delta_pToverpT1']['fit_stats']['mean_err_ls'][-1])\n",
    "\n",
    "al=1  # alpha=0 is transparent\n",
    "elw=1  # error bar line width\n",
    "ecolor='k'\n",
    "ms=4  # marker size\n",
    "mec='k'  # marker edge color\n",
    "cs=1  # cap size\n",
    "mew=0.7  # marker edge width\n",
    "\n",
    "low_x_err, high_x_err = calc_x_err_bins(d0_bin_arr_shifted)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12.8,9.6))\n",
    "\n",
    "# legend_text = \"\"\n",
    "# ax.text(k, y, \"Some words\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "#             legend_text = f'{example_gr.pT_range[0]} <' + r' $p_T$ ' + f'< {example_gr.pT_range[1]}'\n",
    "ax.errorbar(d0_bin_arr_shifted, fit_mean_ls, xerr=[low_x_err, high_x_err], \n",
    "            yerr=fit_mean_err_ls, fmt='s', label=\"some cuts go here?\",\n",
    "        #color=color_dict[count], \n",
    "            elinewidth=elw, ms=ms, markeredgecolor=mec, capsize=cs, mew=mew, ecolor=ecolor)\n",
    "ax.legend(loc='upper left', framealpha=al)#, fontsize=text_size_legend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
